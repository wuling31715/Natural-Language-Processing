{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.1 Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.params = list() \n",
    "        self.grads = list()\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = softmax(x)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = self.out * dout\n",
    "        sumdx = np.sum(dx, axis=1, keepdims=True)\n",
    "        dx -= self.out * sumdx\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.2 Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\frac{\\partial L}{\\partial X} = (\\frac{\\partial L}{\\partial x_1}, \\frac{\\partial L}{\\partial x_2}... \\frac{\\partial L}{\\partial x_n})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.3 Chain Lule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\frac{\\partial X}{\\partial Z} = \\frac{\\partial X}{\\partial Y} \\frac{\\partial Y}{\\partial Z}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.4 Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.4.1 Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.4.2 Branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.4.3 Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "[[ 1.28405252  0.58775303 -0.32320597 -0.24592034 -1.58843073  0.71912418\n",
      "   0.21437496  0.10524601]]\n",
      "\n",
      "y:\n",
      "[[ 1.28405252  0.58775303 -0.32320597 -0.24592034 -1.58843073  0.71912418\n",
      "   0.21437496  0.10524601]\n",
      " [ 1.28405252  0.58775303 -0.32320597 -0.24592034 -1.58843073  0.71912418\n",
      "   0.21437496  0.10524601]\n",
      " [ 1.28405252  0.58775303 -0.32320597 -0.24592034 -1.58843073  0.71912418\n",
      "   0.21437496  0.10524601]\n",
      " [ 1.28405252  0.58775303 -0.32320597 -0.24592034 -1.58843073  0.71912418\n",
      "   0.21437496  0.10524601]\n",
      " [ 1.28405252  0.58775303 -0.32320597 -0.24592034 -1.58843073  0.71912418\n",
      "   0.21437496  0.10524601]\n",
      " [ 1.28405252  0.58775303 -0.32320597 -0.24592034 -1.58843073  0.71912418\n",
      "   0.21437496  0.10524601]\n",
      " [ 1.28405252  0.58775303 -0.32320597 -0.24592034 -1.58843073  0.71912418\n",
      "   0.21437496  0.10524601]]\n",
      "\n",
      "dy:\n",
      "[[ 2.26892824e-01  8.78954825e-02  9.95837408e-01 -1.23953429e+00\n",
      "  -1.96653140e-01 -5.65898803e-01  1.11190767e+00  1.10404209e-01]\n",
      " [-5.75998879e-01  4.07007862e-01  7.94090381e-01 -1.73360991e+00\n",
      "  -2.18922584e+00  9.57525738e-01  2.08748426e+00  1.26911942e-01]\n",
      " [ 1.05736002e+00  2.48765090e-02  9.06228983e-01  2.47998688e-01\n",
      "   5.57160613e-01 -4.47816002e-01  9.55014440e-01 -8.20364294e-01]\n",
      " [-1.18210046e+00 -6.78719827e-01 -1.73148410e-01 -1.14709327e-03\n",
      "  -2.11690853e+00 -6.07581370e-01  7.94635238e-01 -3.36574469e-01]\n",
      " [ 5.58494927e-01 -8.47562039e-02 -7.12657347e-01 -1.03567722e+00\n",
      "  -6.48368237e-01  1.63544247e+00  2.48239937e-01  1.65299375e+00]\n",
      " [ 6.92167569e-01 -1.95656626e+00  5.36395260e-01 -2.19289834e+00\n",
      "   2.02199127e+00  8.51585650e-01 -1.08008695e+00  7.60376711e-01]\n",
      " [ 6.60286024e-02  2.52952469e+00  2.08309423e+00 -7.97919699e-01\n",
      "   8.87419026e-01 -1.56195182e+00  1.00827806e+00  4.38393206e-01]]\n",
      "\n",
      "dx:\n",
      "[[ 0.8428446   0.32926225  4.4298405  -6.75278786 -1.68458484  0.26130586\n",
      "   5.12547265  1.93214105]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "D = 8\n",
    "N = 7\n",
    "x = np.random.randn(1, D)\n",
    "y = np.repeat(x, N, axis=0) # forward\n",
    "dy = np.random.randn(N, D) # gradient\n",
    "dx = np.sum(dy, axis=0, keepdims=True) # backward\n",
    "print(\"x:\\n{}\\n\".format(x))\n",
    "print(\"y:\\n{}\\n\".format(y))\n",
    "print(\"dy:\\n{}\\n\".format(dy))\n",
    "print(\"dx:\\n{}\\n\".format(dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.4.4 Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "[[-7.83305840e-01  1.92923045e+00  1.01195494e+00 -2.48230715e+00\n",
      "  -4.64231228e-01  5.91175188e-01 -1.05315748e+00 -2.43263158e-01]\n",
      " [ 4.05977843e-01 -1.29147865e-01 -6.43595989e-01 -3.56481684e-01\n",
      "   6.20339673e-01 -9.44876426e-01  1.25960861e-01 -1.21731849e+00]\n",
      " [ 9.37413472e-01 -1.22735298e-01  8.84076947e-01 -2.21324316e+00\n",
      "   5.83968267e-01 -5.52866284e-01 -4.12653854e-01  6.11186712e-01]\n",
      " [ 4.36352801e-01  8.65204086e-02  2.38662097e+00  1.85428891e+00\n",
      "  -6.86274353e-01  1.34136547e+00 -8.79451006e-02  4.47950860e-01]\n",
      " [ 8.97627315e-01 -1.01200808e+00  1.03082072e+00 -4.54829598e-01\n",
      "  -2.60245819e+00 -3.38569064e-01 -1.45478630e+00  8.42820579e-01]\n",
      " [ 1.39205722e+00  6.04158962e-01  1.74783174e+00  4.62525015e-01\n",
      "  -1.70016011e-01  3.12720185e-01 -1.84952344e+00 -7.45711631e-01]\n",
      " [-2.17191295e-01 -3.59215003e-02 -8.34022953e-02 -1.43487915e+00\n",
      "  -2.13531550e+00 -1.56574643e+00  4.76681662e-04  7.08486003e-01]]\n",
      "\n",
      "y:\n",
      "[[ 3.06893152  1.32009708  6.33430703 -4.62492682 -4.85398734 -1.15679736\n",
      "  -4.73162863  0.40415087]]\n",
      "\n",
      "dy:\n",
      "[[-0.63705004  2.85779927 -0.66807654  0.56854135  1.64790139  0.88026066\n",
      "  -0.44256697  1.28046147]]\n",
      "\n",
      "dx:\n",
      "[[-0.63705004  2.85779927 -0.66807654  0.56854135  1.64790139  0.88026066\n",
      "  -0.44256697  1.28046147]\n",
      " [-0.63705004  2.85779927 -0.66807654  0.56854135  1.64790139  0.88026066\n",
      "  -0.44256697  1.28046147]\n",
      " [-0.63705004  2.85779927 -0.66807654  0.56854135  1.64790139  0.88026066\n",
      "  -0.44256697  1.28046147]\n",
      " [-0.63705004  2.85779927 -0.66807654  0.56854135  1.64790139  0.88026066\n",
      "  -0.44256697  1.28046147]\n",
      " [-0.63705004  2.85779927 -0.66807654  0.56854135  1.64790139  0.88026066\n",
      "  -0.44256697  1.28046147]\n",
      " [-0.63705004  2.85779927 -0.66807654  0.56854135  1.64790139  0.88026066\n",
      "  -0.44256697  1.28046147]\n",
      " [-0.63705004  2.85779927 -0.66807654  0.56854135  1.64790139  0.88026066\n",
      "  -0.44256697  1.28046147]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "D = 8\n",
    "N = 7\n",
    "x = np.random.randn(N, D)\n",
    "y = np.sum(x, axis=0, keepdims=True) # forward\n",
    "dy = np.random.randn(1, D) # gradient\n",
    "dx = np.repeat(dy, N, axis=0) # backward\n",
    "print(\"x:\\n{}\\n\".format(x))\n",
    "print(\"y:\\n{}\\n\".format(y))\n",
    "print(\"dy:\\n{}\\n\".format(dy))\n",
    "print(\"dx:\\n{}\\n\".format(dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.4.5 MatMul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, = self.params\n",
    "        out = np.dot(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        self.grads[0][...] = dW\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.5 Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.5.1 Sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params = list()\n",
    "        self.grads = list()\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.5.2 Affine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.dot(x, W) + b\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, b = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        db = np.sum(dout, axis=0)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.5.3 Softmax with Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params = list()\n",
    "        self.grads = list()\n",
    "        self.y = None  \n",
    "        self.t = None  \n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "\n",
    "        if self.t.size == self.y.size:\n",
    "            self.t = self.t.argmax(axis=1)\n",
    "\n",
    "        loss = cross_entropy_error(self.y, self.t)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "\n",
    "        dx = self.y.copy()\n",
    "        dx[np.arange(batch_size), self.t] -= 1\n",
    "        dx *= dout\n",
    "        dx = dx / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.6 Updating Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr * grads[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = []\n",
    "            for param in params:\n",
    "                self.v.append(np.zeros_like(param))\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            self.v[i] = self.momentum * self.v[i] - self.lr * grads[i]\n",
    "            params[i] += self.v[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nesterov:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = []\n",
    "            for param in params:\n",
    "                self.v.append(np.zeros_like(param))\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            self.v[i] *= self.momentum\n",
    "            self.v[i] -= self.lr * grads[i]\n",
    "            params[i] += self.momentum * self.momentum * self.v[i]\n",
    "            params[i] -= (1 + self.momentum) * self.lr * grads[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = []\n",
    "            for param in params:\n",
    "                self.h.append(np.zeros_like(param))\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            self.h[i] += grads[i] * grads[i]\n",
    "            params[i] -= self.lr * grads[i] / (np.sqrt(self.h[i]) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop:\n",
    "    def __init__(self, lr=0.01, decay_rate = 0.99):\n",
    "        self.lr = lr\n",
    "        self.decay_rate = decay_rate\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = []\n",
    "            for param in params:\n",
    "                self.h.append(np.zeros_like(param))\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            self.h[i] *= self.decay_rate\n",
    "            self.h[i] += (1 - self.decay_rate) * grads[i] * grads[i]\n",
    "            params[i] -= self.lr * grads[i] / (np.sqrt(self.h[i]) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = [], []\n",
    "            for param in params:\n",
    "                self.m.append(np.zeros_like(param))\n",
    "                self.v.append(np.zeros_like(param))\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n",
    "            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])            \n",
    "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
